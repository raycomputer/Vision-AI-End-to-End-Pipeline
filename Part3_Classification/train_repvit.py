import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torch.utils.tensorboard import SummaryWriter
import timm
from tqdm import tqdm
import os
import cv2
import glob
import albumentations as A
from albumentations.pytorch import ToTensorV2

# ==========================================
# ğŸ‘‡ [ìˆ˜ì • 1] ë‚´ê°€ ì›í•˜ëŠ” í´ë˜ìŠ¤ ìˆœì„œ ì§ì ‘ ì •ì˜í•˜ê¸°
# ==========================================
# ì´ ë¦¬ìŠ¤íŠ¸ì˜ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ê°€ ë§¤ê²¨ì§‘ë‹ˆë‹¤.
# 0ë²ˆ: cats, 1ë²ˆ: dogs
TARGET_CLASSES = ['cats', 'dogs'] 

class SimpleClassDataset(Dataset):
    def __init__(self, root_dir, transform=None, target_classes=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_paths = []
        self.labels = []
        
        # [ìˆ˜ì • 2] ì‚¬ìš©ìê°€ ì •ì˜í•œ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ ìš°ì„  ì‚¬ìš©
        if target_classes:
            self.classes = target_classes
            print(f"âœ… ì‚¬ìš©ìê°€ ì§€ì •í•œ í´ë˜ìŠ¤ ìˆœì„œë¥¼ ë”°ë¦…ë‹ˆë‹¤: {self.classes}")
        else:
            # ì§€ì • ì•ˆ í•˜ë©´ ê¸°ì¡´ì²˜ëŸ¼ í´ë” ì½ì–´ì„œ ìë™ ì •ë ¬
            self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])
            print(f"ğŸ“‚ í´ë”ë¥¼ ì½ì–´ ìë™ìœ¼ë¡œ í´ë˜ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤: {self.classes}")

        # ë°ì´í„° ë¡œë“œ (ì§€ì •ëœ í´ë˜ìŠ¤ í´ë”ë§Œ ì½ìŒ)
        for label_idx, class_name in enumerate(self.classes):
            class_dir = os.path.join(root_dir, class_name)
            
            # í´ë”ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸
            if not os.path.exists(class_dir):
                print(f"âš ï¸ ê²½ê³ : '{class_name}' í´ë”ê°€ {root_dir} ì•ˆì— ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                continue

            # jpg, png, jpeg íŒŒì¼ ëª¨ë‘ ì°¾ê¸°
            files = glob.glob(os.path.join(class_dir, "*.*"))
            files = [f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
            
            for f in files:
                self.image_paths.append(f)
                self.labels.append(label_idx)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        # ì´ë¯¸ì§€ ì½ê¸° ë° ì˜ˆì™¸ ì²˜ë¦¬
        image = cv2.imread(img_path)
        if image is None:
            # ê¹¨ì§„ ì´ë¯¸ì§€ëŠ” ê²€ì€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´ (ì—ëŸ¬ ë°©ì§€)
            image = np.zeros((224, 224, 3), dtype=np.uint8)
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']

        return image, label

def get_transforms():
    return A.Compose([
        A.Resize(224, 224),
        A.HorizontalFlip(p=0.5),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ])

def train_model(data_dir, epochs=5, batch_size=4, lr=1e-4):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ’» í•™ìŠµ ì¥ì¹˜: {device}")

    train_dir = os.path.join(data_dir, 'train')
    
    # [ìˆ˜ì • 3] ë°ì´í„°ì…‹ ìƒì„± ì‹œ ìš°ë¦¬ê°€ ì •ì˜í•œ ë¦¬ìŠ¤íŠ¸(TARGET_CLASSES) ì „ë‹¬
    dataset = SimpleClassDataset(train_dir, transform=get_transforms(), target_classes=TARGET_CLASSES)
    
    if len(dataset) == 0:
        print("âŒ í•™ìŠµí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í´ë” ê²½ë¡œì™€ í´ë˜ìŠ¤ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    num_classes = len(dataset.classes)
    
    print(f"ğŸ“Š ì´ ì´ë¯¸ì§€: {len(dataset)}ì¥")
    print(f"ğŸ¯ í´ë˜ìŠ¤ ë§¤í•‘: {dict(zip(range(num_classes), dataset.classes))}") 
    # ì¶œë ¥ ì˜ˆì‹œ: {0: 'cats', 1: 'dogs'}

    # RepViT ëª¨ë¸ ë¡œë“œ
    model_name = 'repvit_m1_0' 
    print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘... ({model_name})")
    
    try:
        model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)
    except Exception as e:
        print(f"âš ï¸ RepViT ë¡œë“œ ì‹¤íŒ¨ ({e}), EfficientNetìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)

    model = model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    writer = SummaryWriter(log_dir=f'runs/{model_name}_fixed_class')

    model.train()
    print("\nğŸš€ í•™ìŠµ ì‹œì‘!")
    
    for epoch in range(epochs):
        running_loss = 0.0
        correct = 0
        total = 0
        progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
        
        for images, labels in progress_bar:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            progress_bar.set_postfix({'loss': loss.item()})

        scheduler.step()
        epoch_loss = running_loss / len(dataloader)
        epoch_acc = correct / total
        
        writer.add_scalar('Loss/train', epoch_loss, epoch)
        writer.add_scalar('Accuracy/train', epoch_acc, epoch)
        print(f"   [ê²°ê³¼] Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc*100:.2f}%")

    writer.close()
    torch.save(model.state_dict(), "results/repvit_finetuned.pth")
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ë¨.")

if __name__ == "__main__":
    # ë°ì´í„° í´ë” ê²½ë¡œ (./data ì•ˆì— train í´ë”ê°€ ìˆì–´ì•¼ í•¨)
    train_model(data_dir='../data')